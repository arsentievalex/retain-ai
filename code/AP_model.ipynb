{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "35fc22f1-d9d1-4b4a-973b-a85ef1a59423",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import necessary libraries\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "# For data preprocessing\n",
    "from sklearn.preprocessing import OneHotEncoder, StandardScaler\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.impute import SimpleImputer\n",
    "\n",
    "# For model building\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.svm import SVC\n",
    "\n",
    "# For evaluation\n",
    "from sklearn.metrics import accuracy_score, classification_report, confusion_matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "9ce4fb6c-ad6f-4684-aabc-d2288915c01d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Read the training and test data\n",
    "train_df = pd.read_csv('/project/data/employee_data_train.csv')\n",
    "test_df = pd.read_csv('/project/data/employee_data_test.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "7aca2616-9fb8-4471-a871-a544f0e5fc6b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Combine train and test data for consistent preprocessing\n",
    "combined_df = pd.concat([train_df, test_df], sort=False)\n",
    "\n",
    "# Drop irrelevant columns\n",
    "drop_cols = ['Employee Name', 'Employee ID', 'Start Date', 'End Date']\n",
    "combined_df = combined_df.drop(drop_cols, axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "1cfeda3c-44af-4967-b6cd-a842d65bab57",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Feature Engineering\n",
    "def feature_engineering(df):\n",
    "    # Salary Percentage Change\n",
    "    df['Salary Percentage Change'] = (df['Current Salary'] - df['Starting Salary']) / df['Starting Salary']\n",
    "\n",
    "    # Salary Raise Per Year\n",
    "    # To avoid division by zero, add a small epsilon where Tenure is zero\n",
    "    epsilon = 1e-6\n",
    "    df['Adjusted Tenure'] = df['Tenure'].apply(lambda x: x if x > 0 else epsilon)\n",
    "    df['Salary Raise Per Year'] = (df['Current Salary'] - df['Starting Salary']) / df['Adjusted Tenure']\n",
    "\n",
    "    # Promotion Frequency\n",
    "    df['Promotion Frequency'] = df['Promotion History'] / df['Adjusted Tenure']\n",
    "\n",
    "    # Drop the Adjusted Tenure column as it's no longer needed\n",
    "    df = df.drop('Adjusted Tenure', axis=1)\n",
    "\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "1a19529e-adfb-406d-9492-9dcf15df15fa",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Apply feature engineering\n",
    "combined_df = feature_engineering(combined_df)\n",
    "\n",
    "# Update numerical features to include new features\n",
    "numerical_features = ['Age', 'Tenure', 'Starting Salary', 'Current Salary',\n",
    "                      'Years of Experience', 'Average Monthly Working Hours',\n",
    "                      'Months in Role', 'Promotion History', 'Last Performance Review Score',\n",
    "                      'Salary Percentage Change', 'Salary Raise Per Year', 'Promotion Frequency']\n",
    "\n",
    "# Identify categorical features\n",
    "categorical_features = ['Gender', 'Role', 'Department', 'Location', 'Contract']\n",
    "\n",
    "# Separate features and target variable\n",
    "X = combined_df.drop('Turnover', axis=1)\n",
    "y = combined_df['Turnover']\n",
    "\n",
    "# Split back into train and test sets\n",
    "X_train = X.iloc[:len(train_df)]\n",
    "X_test = X.iloc[len(train_df):]\n",
    "y_train = y.iloc[:len(train_df)]\n",
    "y_test = y.iloc[len(train_df):]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "daa3c40a-d20b-4fd1-82a4-80f2559be0c6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the preprocessing steps with imputation\n",
    "numeric_transformer = Pipeline(steps=[\n",
    "    ('imputer', SimpleImputer(strategy='median')),\n",
    "    ('scaler', StandardScaler())\n",
    "])\n",
    "\n",
    "categorical_transformer = Pipeline(steps=[\n",
    "    ('imputer', SimpleImputer(strategy='most_frequent')),\n",
    "    ('onehot', OneHotEncoder(handle_unknown='ignore'))\n",
    "])\n",
    "\n",
    "preprocessor = ColumnTransformer(\n",
    "    transformers=[\n",
    "        ('num', numeric_transformer, numerical_features),\n",
    "        ('cat', categorical_transformer, categorical_features)\n",
    "    ])\n",
    "\n",
    "# Create the pipeline with preprocessing and model\n",
    "model = RandomForestClassifier(random_state=42)\n",
    "\n",
    "pipeline = Pipeline(steps=[\n",
    "    ('preprocessor', preprocessor),\n",
    "    ('classifier', model)\n",
    "])\n",
    "\n",
    "# Hyperparameter tuning using GridSearchCV\n",
    "param_grid = {\n",
    "    'classifier__n_estimators': [100, 200],\n",
    "    'classifier__max_depth': [None, 10, 20],\n",
    "    'classifier__min_samples_split': [2, 5],\n",
    "    'classifier__min_samples_leaf': [1, 2]\n",
    "}\n",
    "\n",
    "grid_search = GridSearchCV(estimator=pipeline, param_grid=param_grid, cv=5, n_jobs=-1, scoring='accuracy')\n",
    "grid_search.fit(X_train, y_train)\n",
    "\n",
    "# Best model from GridSearchCV\n",
    "best_model = grid_search.best_estimator_\n",
    "\n",
    "# Verify the model on unseen test data\n",
    "y_pred = best_model.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "ee2d181b-04d9-4721-9c65-f19031e55629",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy on test data: 0.78\n"
     ]
    }
   ],
   "source": [
    "# Check accuracy\n",
    "accuracy = accuracy_score(y_test, y_pred)\n",
    "print(f\"Accuracy on test data: {accuracy:.2f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "4f68edeb-9d3f-4934-9ddd-c3684e84bdd3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.84      0.89      0.86        75\n",
      "           1       0.55      0.46      0.50        24\n",
      "           4       0.00      0.00      0.00         1\n",
      "\n",
      "    accuracy                           0.78       100\n",
      "   macro avg       0.46      0.45      0.45       100\n",
      "weighted avg       0.76      0.78      0.77       100\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/workbench/.local/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1531: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "/home/workbench/.local/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1531: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "/home/workbench/.local/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1531: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n"
     ]
    }
   ],
   "source": [
    "# Classification report\n",
    "print(\"Classification Report:\")\n",
    "print(classification_report(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "845bba49-0109-4f3b-9a09-8d4ad065882b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Confusion Matrix:\n",
      "[[67  8  0]\n",
      " [13 11  0]\n",
      " [ 0  1  0]]\n"
     ]
    }
   ],
   "source": [
    "# Confusion matrix\n",
    "print(\"Confusion Matrix:\")\n",
    "print(confusion_matrix(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "acf874eb-200a-4613-b4f6-2eed40c57bfa",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to predict attrition probability on new data\n",
    "def predict_attrition(data, model):\n",
    "    \"\"\"\n",
    "    Accepts a dataframe with the same columns as training data,\n",
    "    runs the model per each employee, and returns the dataframe\n",
    "    with one new column with attrition probability.\n",
    "    \"\"\"\n",
    "    # Keep a copy of the original data\n",
    "    data_original = data.copy()\n",
    "\n",
    "    # Drop irrelevant columns\n",
    "    data = data.drop(drop_cols, axis=1)\n",
    "\n",
    "    # Apply feature engineering\n",
    "    data = feature_engineering(data)\n",
    "\n",
    "    # Check if all required columns are present\n",
    "    required_columns = numerical_features + categorical_features\n",
    "    missing_cols = set(required_columns) - set(data.columns)\n",
    "    if missing_cols:\n",
    "        raise ValueError(f\"The following required columns are missing: {missing_cols}\")\n",
    "\n",
    "    # The pipeline handles preprocessing and missing values\n",
    "    probabilities = model.predict_proba(data)[:, 1]  # Probability of class '1' (attrition)\n",
    "\n",
    "    # Add probabilities to the original dataframe\n",
    "    data_original['Attrition Probability'] = probabilities\n",
    "\n",
    "    return data_original"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "239737e9-cac4-4c14-b668-0c31867cd8bf",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Extract feature importances and corresponding feature names\n",
    "def get_feature_importances(best_model, categorical_features):\n",
    "    \"\"\"\n",
    "    Retrieves feature importances from the Random Forest model and maps them to feature names.\n",
    "    Returns a sorted list of tuples (feature_name, importance).\n",
    "    \"\"\"\n",
    "    # Get the feature importances from the classifier in the fitted model\n",
    "    importances = best_model.named_steps['classifier'].feature_importances_\n",
    "\n",
    "    # Get the preprocessor from the fitted model\n",
    "    preprocessor = best_model.named_steps['preprocessor']\n",
    "\n",
    "    # Get the numerical feature names\n",
    "    num_features = preprocessor.transformers[0][2]\n",
    "\n",
    "    # Get the fitted OneHotEncoder and retrieve the categorical feature names\n",
    "    onehot_encoder = preprocessor.named_transformers_['cat'].named_steps['onehot']\n",
    "    onehot_feature_names = onehot_encoder.get_feature_names_out(categorical_features)\n",
    "\n",
    "    # Combine numerical and categorical feature names\n",
    "    feature_names = np.concatenate([num_features, onehot_feature_names])\n",
    "\n",
    "    # Create a dictionary mapping feature names to their importances\n",
    "    feature_importance_dict = dict(zip(feature_names, importances))\n",
    "\n",
    "    # Sort the features by importance\n",
    "    sorted_features = sorted(feature_importance_dict.items(), key=lambda x: x[1], reverse=True)\n",
    "\n",
    "    return sorted_features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "08044ca5-971c-422e-9ad0-d7c8b9c1ea0e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Top 10 Features by Importance:\n",
      "Tenure: 0.1464\n",
      "Salary Raise Per Year: 0.1130\n",
      "Current Salary: 0.0741\n",
      "Starting Salary: 0.0715\n",
      "Salary Percentage Change: 0.0714\n",
      "Age: 0.0693\n",
      "Average Monthly Working Hours: 0.0693\n",
      "Promotion Frequency: 0.0688\n",
      "Months in Role: 0.0661\n",
      "Years of Experience: 0.0652\n"
     ]
    }
   ],
   "source": [
    "# Now use the best_model (from grid_search.best_estimator_) to get feature importances\n",
    "feature_importances = get_feature_importances(grid_search.best_estimator_, categorical_features)\n",
    "\n",
    "# Print the top 10 features\n",
    "print(\"\\nTop 10 Features by Importance:\")\n",
    "for feature, importance in feature_importances[:10]:\n",
    "    print(f\"{feature}: {importance:.4f}\")\n",
    "\n",
    "# export top 10 features to a csv file\n",
    "feature_importances_df = pd.DataFrame(feature_importances[:10], columns=['Feature', 'Importance'])\n",
    "# feature_importances_df.to_csv('feature_importance.csv', index=False)\n",
    "\n",
    "# run on unseen data\n",
    "new_data_df = pd.read_csv('/project/data/employee_data_test.csv')\n",
    "result_df = predict_attrition(new_data_df, best_model)\n",
    "\n",
    "# print(result_df[['Employee ID', 'Attrition Probability']])\n",
    "\n",
    "# result_df.to_csv('predicted_ap.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c3d8cc0e-3d6f-4f41-bf49-bd74b49b74a5",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
